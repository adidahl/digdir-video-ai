{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Video transcription with OpenAI Whisper\n",
        "\n",
        "This notebook will:\n",
        "- Install and set up OpenAI Whisper\n",
        "- Configure two local video files\n",
        "- Transcribe them with timestamps\n",
        "- Save the transcription (with timelines) to a JSONL file for later use (e.g. vector / graph DB).\n",
        "\n",
        "Whisper docs: [openai/whisper GitHub repo](https://github.com/openai/whisper)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting more-itertools (from openai-whisper)\n",
            "  Using cached more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting numba (from openai-whisper)\n",
            "  Downloading numba-0.62.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (2.8 kB)\n",
            "Collecting numpy (from openai-whisper)\n",
            "  Downloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting torch (from openai-whisper)\n",
            "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
            "Collecting tqdm (from openai-whisper)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba->openai-whisper)\n",
            "  Downloading llvmlite-0.45.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (4.8 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
            "  Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting requests>=2.26.0 (from tiktoken->openai-whisper)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
            "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting filelock (from torch->openai-whisper)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->openai-whisper)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch->openai-whisper)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->openai-whisper)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch->openai-whisper)\n",
            "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch->openai-whisper)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->openai-whisper)\n",
            "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->openai-whisper)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper)\n",
            "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
            "Using cached more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
            "Downloading numba-0.62.1-cp313-cp313-macosx_12_0_arm64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.45.1-cp313-cp313-macosx_12_0_arm64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.12.0-cp313-cp313-macosx_11_0_arm64.whl (993 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=2b6bd02a52048391fc094668d12892f79cf6bd72999b46f713e18c1c3008b2b0\n",
            "  Stored in directory: /Users/adi/Library/Caches/pip/wheels/ca/58/d5/fb4539ad74c3ca81eb40f7eda020ac77d080b33ad57449d485\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, regex, numpy, networkx, more-itertools, MarkupSafe, llvmlite, idna, fsspec, filelock, charset_normalizer, certifi, requests, numba, jinja2, torch, tiktoken, openai-whisper\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [openai-whisper]m [torch]t_normalizer]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.10.0 idna-3.11 jinja2-3.1.6 llvmlite-0.45.1 more-itertools-10.8.0 mpmath-1.3.0 networkx-3.6 numba-0.62.1 numpy-2.3.5 openai-whisper-20250625 regex-2025.11.3 requests-2.32.5 setuptools-80.9.0 sympy-1.14.0 tiktoken-0.12.0 torch-2.9.1 tqdm-4.67.1 typing-extensions-4.15.0 urllib3-2.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install Whisper (run this once in your environment)\n",
        "# If you are in a virtualenv, make sure it is activated before running this.\n",
        "\n",
        "%pip install -U openai-whisper\n",
        "\n",
        "# On macOS, Whisper also needs ffmpeg installed at the system level.\n",
        "# If you don't have it yet, install via Homebrew in a terminal (NOT in this cell):\n",
        "#   brew install ffmpeg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "ffmpeg found at: /opt/homebrew/bin/ffmpeg\n",
            "Loading Whisper model: large on cpu ...\n",
            "Model loaded.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import whisper\n",
        "\n",
        "# Choose the Whisper model size.\n",
        "# Options include: \"tiny\", \"base\", \"small\", \"medium\", \"large\", \"turbo\".\n",
        "# See model table in the Whisper README: https://github.com/openai/whisper\n",
        "MODEL_NAME = \"large\"  # adjust if you want faster (\"tiny\") or more accurate (\"medium\"/\"large\")\n",
        "\n",
        "# Device selection\n",
        "# NOTE: Whisper on Apple Silicon (MPS) can sometimes produce NaNs.\n",
        "# To keep things stable, we force CPU here. Set FORCE_DEVICE to None to auto-detect.\n",
        "FORCE_DEVICE = \"cpu\"  # options: \"cpu\", \"cuda\", \"mps\", or None for auto\n",
        "\n",
        "if FORCE_DEVICE is not None:\n",
        "    DEVICE = FORCE_DEVICE\n",
        "else:\n",
        "    if torch.cuda.is_available():\n",
        "        DEVICE = \"cuda\"\n",
        "    elif getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available():\n",
        "        DEVICE = \"mps\"  # Apple Silicon GPU\n",
        "    else:\n",
        "        DEVICE = \"cpu\"\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Check that ffmpeg is available on the system\n",
        "ffmpeg_path = shutil.which(\"ffmpeg\")\n",
        "if ffmpeg_path is None:\n",
        "    print(\"ffmpeg was NOT found on PATH. Please install it, e.g. with: brew install ffmpeg\")\n",
        "else:\n",
        "    print(f\"ffmpeg found at: {ffmpeg_path}\")\n",
        "\n",
        "print(f\"Loading Whisper model: {MODEL_NAME} on {DEVICE} ...\")\n",
        "model = whisper.load_model(MODEL_NAME, device=DEVICE)\n",
        "print(\"Model loaded.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video1: exists=True -> /Users/adi/digdir-video-ai/videos/video1.mp4\n",
            "video2: exists=True -> /Users/adi/digdir-video-ai/videos/video2.mp4\n"
          ]
        }
      ],
      "source": [
        "# Configure paths to your two local video files.\n",
        "# Edit these strings to point to the actual files on your Mac.\n",
        "\n",
        "video1_path = Path(\"/Users/adi/digdir-video-ai/videos/video1.mp4\")\n",
        "video2_path = Path(\"/Users/adi/digdir-video-ai/videos/video2.mp4\")\n",
        "\n",
        "videos = [\n",
        "    {\"id\": \"video1\", \"path\": video1_path},\n",
        "    {\"id\": \"video2\", \"path\": video2_path},\n",
        "]\n",
        "\n",
        "for v in videos:\n",
        "    print(f\"{v['id']}: exists={v['path'].exists()} -> {v['path']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "\n",
        "def transcribe_video(\n",
        "    video_path: Path,\n",
        "    *,\n",
        "    language: Optional[str] = None,\n",
        "    model: \"whisper.Whisper\" = model,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Transcribe a single video file with Whisper, keeping segment timestamps.\n",
        "\n",
        "    Returns the full Whisper result dict, which includes:\n",
        "    - \"text\": full transcript\n",
        "    - \"segments\": list of {id, start, end, text, ...}\n",
        "    \"\"\"\n",
        "    print(f\"Transcribing: {video_path}\")\n",
        "    result = model.transcribe(\n",
        "        str(video_path),\n",
        "        language=language,  # set e.g. \"en\" if you know it's English, or leave None for auto-detect\n",
        "        verbose=False,\n",
        "        word_timestamps=False,  # set to True if you want per-word timestamps (requires newer Whisper)\n",
        "    )\n",
        "    print(f\"Transcription finished for {video_path}\")\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing: /Users/adi/digdir-video-ai/videos/video1.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/adi/digdir-video-ai/.venv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected language: Norwegian\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 372268/372268 [20:08<00:00, 308.00frames/s]\n",
            "/Users/adi/digdir-video-ai/.venv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription finished for /Users/adi/digdir-video-ai/videos/video1.mp4\n",
            "Transcribing: /Users/adi/digdir-video-ai/videos/video2.mp4\n",
            "Detected language: Norwegian\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 370700/370700 [15:30<00:00, 398.46frames/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription finished for /Users/adi/digdir-video-ai/videos/video2.mp4\n",
            "Saved 1660 segments to /Users/adi/digdir-video-ai/transcripts/transcripts_segments.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Transcribe both videos and save transcripts with segment-level timelines to JSONL.\n",
        "\n",
        "output_dir = Path(\"transcripts\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "jsonl_path = output_dir / \"transcripts_segments.jsonl\"\n",
        "all_segments = []\n",
        "\n",
        "for v in videos:\n",
        "    result = transcribe_video(v[\"path\"])\n",
        "    segments = result.get(\"segments\", [])\n",
        "    for seg in segments:\n",
        "        record = {\n",
        "            \"video_id\": v[\"id\"],\n",
        "            \"video_path\": str(v[\"path\"]),\n",
        "            \"segment_id\": seg.get(\"id\"),\n",
        "            \"start\": seg.get(\"start\"),   # seconds from start of video\n",
        "            \"end\": seg.get(\"end\"),       # seconds from start of video\n",
        "            \"text\": seg.get(\"text\"),\n",
        "        }\n",
        "        all_segments.append(record)\n",
        "\n",
        "with jsonl_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for rec in all_segments:\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Saved {len(all_segments)} segments to {jsonl_path.resolve()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lightrag-hku[api]\n",
            "  Downloading lightrag_hku-1.4.9.8-py3-none-any.whl.metadata (83 kB)\n",
            "Collecting aiohttp (from lightrag-hku[api])\n",
            "  Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
            "Collecting configparser (from lightrag-hku[api])\n",
            "  Downloading configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting future (from lightrag-hku[api])\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting google-genai<2.0.0,>=1.0.0 (from lightrag-hku[api])\n",
            "  Downloading google_genai-1.52.0-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting json_repair (from lightrag-hku[api])\n",
            "  Downloading json_repair-0.54.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nano-vectordb (from lightrag-hku[api])\n",
            "  Downloading nano_vectordb-0.0.4.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from lightrag-hku[api]) (3.6)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from lightrag-hku[api]) (2.3.5)\n",
            "Collecting pandas<2.4.0,>=2.0.0 (from lightrag-hku[api])\n",
            "  Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Collecting pipmaster (from lightrag-hku[api])\n",
            "  Downloading pipmaster-1.0.10-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydantic (from lightrag-hku[api])\n",
            "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
            "Collecting pypinyin (from lightrag-hku[api])\n",
            "  Downloading pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting python-dotenv (from lightrag-hku[api])\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from lightrag-hku[api]) (80.9.0)\n",
            "Collecting tenacity (from lightrag-hku[api])\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tiktoken in ./.venv/lib/python3.13/site-packages (from lightrag-hku[api]) (0.12.0)\n",
            "Collecting xlsxwriter>=3.1.0 (from lightrag-hku[api])\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting openai<3.0.0,>=1.0.0 (from lightrag-hku[api])\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles (from lightrag-hku[api])\n",
            "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ascii_colors (from lightrag-hku[api])\n",
            "  Downloading ascii_colors-0.11.4-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting asyncpg (from lightrag-hku[api])\n",
            "  Downloading asyncpg-0.31.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
            "Collecting distro (from lightrag-hku[api])\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi (from lightrag-hku[api])\n",
            "  Downloading fastapi-0.122.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting httpcore (from lightrag-hku[api])\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting httpx (from lightrag-hku[api])\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter (from lightrag-hku[api])\n",
            "  Downloading jiter-0.12.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting passlib[bcrypt] (from lightrag-hku[api])\n",
            "  Downloading passlib-1.7.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from lightrag-hku[api]) (7.1.3)\n",
            "Collecting PyJWT<3.0.0,>=2.8.0 (from lightrag-hku[api])\n",
            "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting python-jose[cryptography] (from lightrag-hku[api])\n",
            "  Downloading python_jose-3.5.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting python-multipart (from lightrag-hku[api])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytz (from lightrag-hku[api])\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting uvicorn (from lightrag-hku[api])\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in ./.venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.0.0->lightrag-hku[api]) (2.32.5)\n",
            "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in ./.venv/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.0.0->lightrag-hku[api]) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->lightrag-hku[api]) (3.11)\n",
            "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx->lightrag-hku[api]) (2025.11.12)\n",
            "Collecting h11>=0.16 (from httpcore->lightrag-hku[api])\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.0.0->lightrag-hku[api]) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas<2.4.0,>=2.0.0->lightrag-hku[api]) (2.9.0.post0)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.4.0,>=2.0.0->lightrag-hku[api])\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic->lightrag-hku[api])\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic->lightrag-hku[api])\n",
            "  Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic->lightrag-hku[api])\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api]) (2.5.0)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->lightrag-hku[api])\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=2.0.0->lightrag-hku[api]) (1.17.0)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->lightrag-hku[api])\n",
            "  Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from ascii_colors->lightrag-hku[api]) (0.2.14)\n",
            "Collecting starlette<0.51.0,>=0.40.0 (from fastapi->lightrag-hku[api])\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi->lightrag-hku[api])\n",
            "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting bcrypt>=3.1.0 (from passlib[bcrypt]; extra == \"api\"->lightrag-hku[api])\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=21.0 in ./.venv/lib/python3.13/site-packages (from pipmaster->lightrag-hku[api]) (25.0)\n",
            "Collecting ecdsa!=0.15 (from python-jose[cryptography]; extra == \"api\"->lightrag-hku[api])\n",
            "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Collecting cryptography>=3.4.0 (from python-jose[cryptography]; extra == \"api\"->lightrag-hku[api])\n",
            "  Downloading cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
            "Collecting cffi>=2.0.0 (from cryptography>=3.4.0->python-jose[cryptography]; extra == \"api\"->lightrag-hku[api])\n",
            "  Downloading cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
            "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->python-jose[cryptography]; extra == \"api\"->lightrag-hku[api])\n",
            "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken->lightrag-hku[api]) (2025.11.3)\n",
            "Collecting click>=7.0 (from uvicorn->lightrag-hku[api])\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading lightrag_hku-1.4.9.8-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading google_genai-1.52.0-py3-none-any.whl (261 kB)\n",
            "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading jiter-0.12.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\n",
            "Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "Downloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
            "Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl (489 kB)\n",
            "Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
            "Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
            "Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
            "Downloading ascii_colors-0.11.4-py3-none-any.whl (71 kB)\n",
            "Downloading asyncpg-0.31.0-cp313-cp313-macosx_11_0_arm64.whl (636 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.9/636.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configparser-7.2.0-py3-none-any.whl (17 kB)\n",
            "Downloading fastapi-0.122.0-py3-none-any.whl (110 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Downloading json_repair-0.54.1-py3-none-any.whl (29 kB)\n",
            "Downloading nano_vectordb-0.0.4.3-py3-none-any.whl (5.6 kB)\n",
            "Downloading passlib-1.7.4-py2.py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.6/525.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl (495 kB)\n",
            "Downloading pipmaster-1.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading pypinyin-0.55.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading python_jose-3.5.0-py2.py3-none-any.whl (34 kB)\n",
            "Downloading cryptography-46.0.3-cp311-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cffi-2.0.0-cp313-cp313-macosx_11_0_arm64.whl (181 kB)\n",
            "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
            "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Installing collected packages: pytz, passlib, xlsxwriter, websockets, tzdata, typing-inspection, tenacity, sniffio, python-multipart, python-dotenv, pypinyin, PyJWT, pydantic-core, pycparser, pyasn1, propcache, nano-vectordb, multidict, json_repair, jiter, h11, future, frozenlist, ecdsa, distro, configparser, click, cachetools, bcrypt, attrs, asyncpg, ascii_colors, annotated-types, annotated-doc, aiohappyeyeballs, aiofiles, yarl, uvicorn, rsa, pydantic, pyasn1-modules, pipmaster, pandas, httpcore, cffi, anyio, aiosignal, starlette, python-jose, httpx, google-auth, cryptography, aiohttp, openai, google-genai, fastapi, lightrag-hku\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/57\u001b[0m [lightrag-hku]trag-hku]api]enai]s]t]\n",
            "\u001b[1A\u001b[2KSuccessfully installed PyJWT-2.10.1 aiofiles-25.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.11.0 ascii_colors-0.11.4 asyncpg-0.31.0 attrs-25.4.0 bcrypt-5.0.0 cachetools-6.2.2 cffi-2.0.0 click-8.3.1 configparser-7.2.0 cryptography-46.0.3 distro-1.9.0 ecdsa-0.19.1 fastapi-0.122.0 frozenlist-1.8.0 future-1.0.0 google-auth-2.43.0 google-genai-1.52.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 json_repair-0.54.1 lightrag-hku-1.4.9.8 multidict-6.7.0 nano-vectordb-0.0.4.3 openai-2.8.1 pandas-2.3.3 passlib-1.7.4 pipmaster-1.0.10 propcache-0.4.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.12.4 pydantic-core-2.41.5 pypinyin-0.55.0 python-dotenv-1.2.1 python-jose-3.5.0 python-multipart-0.0.20 pytz-2025.2 rsa-4.9.1 sniffio-1.3.1 starlette-0.50.0 tenacity-9.1.2 typing-inspection-0.4.2 tzdata-2025.2 uvicorn-0.38.0 websockets-15.0.1 xlsxwriter-3.2.9 yarl-1.22.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install LightRAG (run this once)\n",
        "# This uses the official LightRAG package from https://github.com/HKUDS/LightRAG\n",
        "\n",
        "%pip install \"lightrag-hku[api]\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.11-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-6.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.13/site-packages (from neo4j) (2025.2)\n",
            "Downloading psycopg2_binary-2.9.11-cp313-cp313-macosx_11_0_arm64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading neo4j-6.0.3-py3-none-any.whl (325 kB)\n",
            "Installing collected packages: psycopg2-binary, neo4j\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [neo4j]32m1/2\u001b[0m [neo4j]\n",
            "\u001b[1A\u001b[2KSuccessfully installed neo4j-6.0.3 psycopg2-binary-2.9.11\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install python-dotenv\n",
        "%pip install psycopg2-binary neo4j\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: [_] Created new empty graph file: ./lightrag_store/graph_chunk_entity_relation.graphml\n",
            "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './lightrag_store/vdb_entities.json'} 0 data\n",
            "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './lightrag_store/vdb_relationships.json'} 0 data\n",
            "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './lightrag_store/vdb_chunks.json'} 0 data\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY is set.\n",
            "POSTGRES_DSN set: True\n",
            "NEO4J_URI set: True\n",
            "LightRAG initialized.\n"
          ]
        }
      ],
      "source": [
        "# Configure LightRAG and external store connection settings\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "\n",
        "from lightrag import LightRAG, QueryParam\n",
        "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
        "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
        "\n",
        "\n",
        "LIGHTRAG_WORK_DIR = \"./lightrag_store\"\n",
        "os.makedirs(LIGHTRAG_WORK_DIR, exist_ok=True)\n",
        "\n",
        "# OpenAI API key (you will set this in your shell, not in the notebook)\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"WARNING: OPENAI_API_KEY is not set. Set it before using LightRAG.\")\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY is set.\")\n",
        "\n",
        "# Postgres and Neo4j connection details (you will configure these via Docker)\n",
        "POSTGRES_DSN = os.getenv(\"POSTGRES_DSN\")  # e.g. postgresql://user:pass@localhost:5432/dbname\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")        # e.g. bolt://localhost:7687\n",
        "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
        "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
        "\n",
        "print(f\"POSTGRES_DSN set: {bool(POSTGRES_DSN)}\")\n",
        "print(f\"NEO4J_URI set: {bool(NEO4J_URI)}\")\n",
        "\n",
        "\n",
        "async def init_lightrag() -> LightRAG:\n",
        "    \"\"\"Initialize a LightRAG instance backed by the local workspace directory.\"\"\"\n",
        "    rag = LightRAG(\n",
        "        working_dir=LIGHTRAG_WORK_DIR,\n",
        "        embedding_func=openai_embed,\n",
        "        llm_model_func=gpt_4o_mini_complete,\n",
        "    )\n",
        "    await rag.initialize_storages()\n",
        "    # Ensure pipeline_status namespace is initialized so ainsert/aquery work\n",
        "    await initialize_pipeline_status()\n",
        "    return rag\n",
        "\n",
        "\n",
        "rag = await init_lightrag()\n",
        "print(\"LightRAG initialized.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Postgres connectivity OK.\n",
            "Neo4j connectivity OK.\n"
          ]
        }
      ],
      "source": [
        "# Optional: quick connectivity checks for Postgres and Neo4j\n",
        "# Requires `psycopg2` (for Postgres) and `neo4j` Python driver to be installed.\n",
        "\n",
        "import importlib\n",
        "\n",
        "\n",
        "def check_postgres():\n",
        "    if not POSTGRES_DSN:\n",
        "        print(\"POSTGRES_DSN not set; skipping Postgres check.\")\n",
        "        return\n",
        "    try:\n",
        "        psycopg2 = importlib.import_module(\"psycopg2\")\n",
        "    except ImportError:\n",
        "        print(\"psycopg2 is not installed; skipping Postgres check.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with psycopg2.connect(POSTGRES_DSN) as conn:\n",
        "            with conn.cursor() as cur:\n",
        "                cur.execute(\"SELECT 1\")\n",
        "        print(\"Postgres connectivity OK.\")\n",
        "    except Exception as e:\n",
        "        print(\"Postgres connectivity failed:\", e)\n",
        "\n",
        "\n",
        "def check_neo4j():\n",
        "    if not (NEO4J_URI and NEO4J_USER and NEO4J_PASSWORD):\n",
        "        print(\"NEO4J_* env vars not fully set; skipping Neo4j check.\")\n",
        "        return\n",
        "    try:\n",
        "        neo4j = importlib.import_module(\"neo4j\")\n",
        "    except ImportError:\n",
        "        print(\"neo4j Python driver is not installed; skipping Neo4j check.\")\n",
        "        return\n",
        "\n",
        "    from neo4j import GraphDatabase\n",
        "\n",
        "    try:\n",
        "        driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "        with driver.session() as session:\n",
        "            session.run(\"RETURN 1\").single()\n",
        "        print(\"Neo4j connectivity OK.\")\n",
        "    except Exception as e:\n",
        "        print(\"Neo4j connectivity failed:\", e)\n",
        "\n",
        "\n",
        "check_postgres()\n",
        "check_neo4j()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1660 contexts from transcripts/transcripts_segments.jsonl.\n",
            "Example context:\n",
            " [video_id=video1;start=0.0;end=29.98;segment_id=0] Vi prøver å ta vare på disse opptakene og hva som er viktig å gjøre. ...\n"
          ]
        }
      ],
      "source": [
        "# Build LightRAG-ready contexts from the timestamped transcript segments\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "transcript_jsonl_path = Path(\"transcripts/transcripts_segments.jsonl\")\n",
        "\n",
        "contexts: list[str] = []\n",
        "contexts_meta: list[dict] = []\n",
        "\n",
        "if not transcript_jsonl_path.exists():\n",
        "    raise FileNotFoundError(f\"Transcript file not found: {transcript_jsonl_path}\")\n",
        "\n",
        "with transcript_jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        rec = json.loads(line)\n",
        "        text = (rec.get(\"text\") or \"\").strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        meta = {\n",
        "            \"video_id\": rec.get(\"video_id\"),\n",
        "            \"video_path\": rec.get(\"video_path\"),\n",
        "            \"segment_id\": rec.get(\"segment_id\"),\n",
        "            \"start\": rec.get(\"start\"),\n",
        "            \"end\": rec.get(\"end\"),\n",
        "        }\n",
        "\n",
        "        header = (\n",
        "            f\"[video_id={meta['video_id']};start={meta['start']};\"\n",
        "            f\"end={meta['end']};segment_id={meta['segment_id']}] \"\n",
        "        )\n",
        "        context = header + text\n",
        "\n",
        "        meta[\"text\"] = text\n",
        "        meta[\"context\"] = context\n",
        "\n",
        "        contexts.append(context)\n",
        "        contexts_meta.append(meta)\n",
        "\n",
        "print(f\"Loaded {len(contexts)} contexts from {transcript_jsonl_path}.\")\n",
        "if contexts:\n",
        "    print(\"Example context:\\n\", contexts[0][:300], \"...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring document ID (already exists): doc-879378d49c3aba1929a7b43d4e9914f9 (unknown_source)\n",
            "WARNING: No new unique documents were found.\n",
            "INFO: Processing 1 document(s)\n",
            "INFO: Extracting stage 1/1: unknown_source\n",
            "INFO: Processing d-id: doc-879378d49c3aba1929a7b43d4e9914f9\n",
            "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserting 1660 contexts into LightRAG (this may take a while)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: LLM func: 4 new workers initialized (Timeouts: Func: 180s, Worker: 360s, Health Check: 375s)\n",
            "INFO:  == LLM cache == saving: default:extract:00ee9fc772ea4f26218812a081da2a65\n",
            "INFO:  == LLM cache == saving: default:extract:6d1d8bdabb0fcb65f1e786315656b367\n",
            "INFO: Chunk 1 of 62 extracted 5 Ent + 4 Rel chunk-6619ecb638d4499a9c23b6b8bd388a40\n",
            "INFO:  == LLM cache == saving: default:extract:c04e39a2793987fc7c0aa15d0e6e9a34\n",
            "INFO:  == LLM cache == saving: default:extract:6bc700e186f181f0d35ecf9863168a69\n",
            "INFO:  == LLM cache == saving: default:extract:b4d7ffe5c7e88c108308e358b0f5ab59\n",
            "INFO: Chunk 2 of 62 extracted 7 Ent + 6 Rel chunk-b340c913e3e67b8dc1a8277ea9eec1e3\n",
            "INFO:  == LLM cache == saving: default:extract:9e1f3a39edd1b61c24326632c6c05016\n",
            "INFO:  == LLM cache == saving: default:extract:e5b96caf9c09438da51842769c357ae4\n",
            "INFO: Chunk 3 of 62 extracted 11 Ent + 8 Rel chunk-5d4cb93be36b654c9f9a556c667e0916\n",
            "INFO:  == LLM cache == saving: default:extract:6856688d894cdfc6f46d183a919096cc\n",
            "INFO: Chunk 4 of 62 extracted 12 Ent + 7 Rel chunk-9515e85d34fed96196f836db2020d559\n",
            "INFO:  == LLM cache == saving: default:extract:649dddb05661bee1ab9b21b8396c51d5\n",
            "INFO:  == LLM cache == saving: default:extract:8295e3c8ce183219a40a4d549ba001ee\n",
            "INFO: Chunk 5 of 62 extracted 8 Ent + 6 Rel chunk-12efbab2e3982b835e7e851d4595af94\n",
            "INFO:  == LLM cache == saving: default:extract:c42a0d0d1ad318cf933379f48862b3cc\n",
            "INFO:  == LLM cache == saving: default:extract:2fb91cc0d09e60367aafa5af865aae78\n",
            "INFO:  == LLM cache == saving: default:extract:dca33501413db496c4cde3aedd6217eb\n",
            "INFO: Chunk 6 of 62 extracted 7 Ent + 6 Rel chunk-5288c81db86953a4b652d99c754d99c5\n",
            "INFO:  == LLM cache == saving: default:extract:94d0218664cabf972b5fed49d7f53f93\n",
            "INFO: Chunk 7 of 62 extracted 8 Ent + 6 Rel chunk-2524e66dc784dd515b4a805e2d684380\n",
            "INFO:  == LLM cache == saving: default:extract:0ea66d53bdce11f25ccbda769b18c81c\n",
            "INFO:  == LLM cache == saving: default:extract:4b56b99f67b37e7ade587986032093c6\n",
            "INFO: Chunk 8 of 62 extracted 8 Ent + 5 Rel chunk-cfd7d387f76867af105018988516a4e0\n",
            "INFO:  == LLM cache == saving: default:extract:348c38f3895c6eede33cd7782ace998c\n",
            "INFO:  == LLM cache == saving: default:extract:37e52627b3b961aaf43a20b27dd0bba5\n",
            "INFO:  == LLM cache == saving: default:extract:c393d0f180070e582f923fdfe9719f08\n",
            "INFO: Chunk 9 of 62 extracted 9 Ent + 6 Rel chunk-13a3a53b74f877421f187e614d13964b\n",
            "INFO:  == LLM cache == saving: default:extract:9158c6adcb6f6f9e1cfc86935bc8dcef\n",
            "INFO:  == LLM cache == saving: default:extract:9fb77a34f62323e610edc0884e24d018\n",
            "INFO: Chunk 10 of 62 extracted 8 Ent + 5 Rel chunk-8c99690313bc8d31d23fb7d42bd4dc85\n",
            "INFO:  == LLM cache == saving: default:extract:8337216ad4089aa6713773338f562b4c\n",
            "INFO: Chunk 11 of 62 extracted 8 Ent + 7 Rel chunk-70ce3c761484b44561aec36c0cc8e8b1\n",
            "INFO:  == LLM cache == saving: default:extract:eb1678121906d8055f4ce6cbe8dda670\n",
            "INFO:  == LLM cache == saving: default:extract:7765c8382fb380b06d37b61bbcee4e74\n",
            "INFO: Chunk 12 of 62 extracted 9 Ent + 6 Rel chunk-1af5f2bed56146a4d9808f74f4a4cb1c\n",
            "INFO:  == LLM cache == saving: default:extract:7818896950b22fc87f393961f8e83909\n",
            "INFO:  == LLM cache == saving: default:extract:6b0b0a77705a2c37e4ef3436a9b6ced0\n",
            "INFO: Chunk 13 of 62 extracted 10 Ent + 7 Rel chunk-4bbb25c78ffc9fcbd212e62c4ab5f389\n",
            "INFO:  == LLM cache == saving: default:extract:727d4224f4c082b47fed1c63429e5a27\n",
            "INFO:  == LLM cache == saving: default:extract:fcffda08506e385ce2be46109aa17857\n",
            "INFO: Chunk 14 of 62 extracted 9 Ent + 7 Rel chunk-2f10e1c7eacdc775dc9644fe141f1504\n",
            "INFO:  == LLM cache == saving: default:extract:1058b0ac586e811ed71ef622df204841\n",
            "INFO:  == LLM cache == saving: default:extract:b554230c0fa871195f967409ddc2144f\n",
            "INFO:  == LLM cache == saving: default:extract:5f87b8843a5d0097e411a7faa01e579b\n",
            "INFO: Chunk 15 of 62 extracted 8 Ent + 7 Rel chunk-89fa240103d66bc9f06f5f038ae8fe4a\n",
            "INFO:  == LLM cache == saving: default:extract:a78d407feaf8db9597b9bf43c57b2255\n",
            "INFO:  == LLM cache == saving: default:extract:3c3712bb94ac3816ce6c8cf1f500ae80\n",
            "INFO: Chunk 16 of 62 extracted 10 Ent + 6 Rel chunk-95887e3e5e8499288119cf88aedbeae6\n",
            "INFO:  == LLM cache == saving: default:extract:3ca29231db8266ae1524f6d753c37944\n",
            "INFO:  == LLM cache == saving: default:extract:92fb35f345463a6e7025f699f04cba91\n",
            "INFO: Chunk 17 of 62 extracted 7 Ent + 7 Rel chunk-74e0d4ab3e9bbf68e942aa1ddbc85d30\n",
            "INFO:  == LLM cache == saving: default:extract:13dcde397fbe729e5d33187ad1fba2ee\n",
            "INFO: Chunk 18 of 62 extracted 8 Ent + 5 Rel chunk-365c683d759ec3ead5b332c6e8aaca76\n",
            "INFO:  == LLM cache == saving: default:extract:1f8a93de3c3f1b6f8e986c94bc19ef47\n",
            "INFO:  == LLM cache == saving: default:extract:940c7db3aee4c0f8fbf5ae2538343c4b\n",
            "INFO:  == LLM cache == saving: default:extract:480c2d1bfba6955666279746f126b7fd\n",
            "INFO: Chunk 19 of 62 extracted 6 Ent + 5 Rel chunk-3b3baf5ccc0d2339197e53af5392ce98\n",
            "INFO:  == LLM cache == saving: default:extract:914f095b2f85ab35f480d1baf0bf557d\n",
            "INFO: Chunk 20 of 62 extracted 6 Ent + 5 Rel chunk-abb2bb922fd814e0bc2db16e84f16a0b\n",
            "INFO:  == LLM cache == saving: default:extract:cee06432276921bb426c72569185e118\n",
            "INFO:  == LLM cache == saving: default:extract:39984fc9a154d2f6dc99a58f298e42b8\n",
            "INFO:  == LLM cache == saving: default:extract:4e61ee839fc8482ca65d612528c08c86\n",
            "INFO:  == LLM cache == saving: default:extract:46de3970e3cf9240b7777fdcfec450cc\n",
            "INFO: Chunk 21 of 62 extracted 10 Ent + 8 Rel chunk-10a76ac4c95d39177e0a385ff8317f5c\n",
            "INFO:  == LLM cache == saving: default:extract:2adb369728a16df9938843aa36f089c9\n",
            "INFO:  == LLM cache == saving: default:extract:e7fc6e840522edc672390cd30fae4835\n",
            "INFO: Chunk 22 of 62 extracted 10 Ent + 6 Rel chunk-7e5bd40df3bf8b585fb0552167b5f814\n",
            "INFO:  == LLM cache == saving: default:extract:ce42959b1f781b237ea638db5597f2fb\n",
            "INFO: Chunk 23 of 62 extracted 9 Ent + 7 Rel chunk-76318d9f134ce5ee9ed9dd2e7de911e5\n",
            "INFO:  == LLM cache == saving: default:extract:ee41413f5e5a516a72c3d8cdd089016d\n",
            "INFO: Chunk 24 of 62 extracted 10 Ent + 6 Rel chunk-068813d4b9958ecbdb54c3dc43124287\n",
            "INFO:  == LLM cache == saving: default:extract:eccb77208a2feb02ed4c9d903f827087\n",
            "INFO:  == LLM cache == saving: default:extract:fc491f29a044ba5b0645adc3fe7dc9cf\n",
            "INFO:  == LLM cache == saving: default:extract:26a7015e2dd8c1de60cc53737990111c\n",
            "INFO: Chunk 25 of 62 extracted 7 Ent + 6 Rel chunk-b33fc8213b6a295bbeded9068399da01\n",
            "INFO:  == LLM cache == saving: default:extract:63b18cf23d37bf5989cd6f5b77a4cc46\n",
            "INFO:  == LLM cache == saving: default:extract:16fa01b4efc5214a862bea62e5c52922\n",
            "INFO: Chunk 26 of 62 extracted 8 Ent + 6 Rel chunk-aa11971183569ba474b54dfeb62bbf44\n",
            "INFO:  == LLM cache == saving: default:extract:213a559f763eb99c9b510ce81b7fd38c\n",
            "INFO: Chunk 27 of 62 extracted 8 Ent + 6 Rel chunk-09a094bd3285aabf3da0bec84dfba164\n",
            "INFO:  == LLM cache == saving: default:extract:bb6d3818891422c596fc443ebe22ad87\n",
            "INFO:  == LLM cache == saving: default:extract:a62c467c2fda983f7942cd987ed3e376\n",
            "INFO:  == LLM cache == saving: default:extract:a626d594a195b8a16e879a28876be15f\n",
            "INFO:  == LLM cache == saving: default:extract:0def2884881ca41197eb6eb5bf6cb487\n",
            "INFO:  == LLM cache == saving: default:extract:01b9269ded9622fe27c88a7b6e136f3a\n",
            "INFO: Chunk 28 of 62 extracted 9 Ent + 7 Rel chunk-6e9b7d9ae4dbe730c6d8406a198dc2a0\n",
            "INFO:  == LLM cache == saving: default:extract:9651bf06453fe1b267e7dbdb5a8a48bc\n",
            "INFO: Chunk 29 of 62 extracted 10 Ent + 6 Rel chunk-0d6981293eae1f572d886894ea835e84\n",
            "INFO:  == LLM cache == saving: default:extract:fce5193ae01f24588a28cb8b3f70c49a\n",
            "INFO: Chunk 30 of 62 extracted 12 Ent + 7 Rel chunk-715515df3f6568c740b285a10d096eb4\n",
            "INFO:  == LLM cache == saving: default:extract:edc61eff54bd8d5b6cace658cf114bf5\n",
            "INFO: Chunk 31 of 62 extracted 10 Ent + 7 Rel chunk-b17661d28b0316e1dd5c1b1851e66875\n",
            "INFO:  == LLM cache == saving: default:extract:c9eb3ce566ca1012c5a07fc168e5da19\n",
            "INFO:  == LLM cache == saving: default:extract:11a2ac12bea1e07576f556c2d039427b\n",
            "INFO:  == LLM cache == saving: default:extract:ad98b4426bc61b7faa49b9e46bc8787b\n",
            "INFO: Chunk 32 of 62 extracted 8 Ent + 6 Rel chunk-8d34cc82a62eadb070e39d50bd74d9b2\n",
            "INFO:  == LLM cache == saving: default:extract:d16b813a67d05480893200976186e91b\n",
            "INFO:  == LLM cache == saving: default:extract:9ba9e94617e62d6b0cc2451e10f74647\n",
            "INFO: Chunk 33 of 62 extracted 8 Ent + 8 Rel chunk-5e2133192283742ec07e0c61028bc6e4\n",
            "INFO:  == LLM cache == saving: default:extract:129132aa7997960c05140a815d3df671\n",
            "INFO:  == LLM cache == saving: default:extract:0b7ec2c17d3b65c6678e239ce76d8b65\n",
            "INFO: Chunk 34 of 62 extracted 12 Ent + 7 Rel chunk-9cb6de3012a3392e968595d1795bcdb9\n",
            "INFO:  == LLM cache == saving: default:extract:df158cdb686ac018afcd2a867f6be6cc\n",
            "INFO:  == LLM cache == saving: default:extract:eabb2a34e44be28380cb2a8882c1d8f9\n",
            "INFO: Chunk 35 of 62 extracted 11 Ent + 9 Rel chunk-9d7f5da6a2486746bc10a7cc595b5d3d\n",
            "INFO:  == LLM cache == saving: default:extract:00aed315a228722e8fd265307cae4236\n",
            "INFO:  == LLM cache == saving: default:extract:77b01b881ebc5edf1ce420409e24725f\n",
            "INFO: Chunk 36 of 62 extracted 7 Ent + 5 Rel chunk-53db088e6b97c4fa8777b0bd799fcdd5\n",
            "INFO:  == LLM cache == saving: default:extract:c488ad01abec303af9cf283f3a07da45\n",
            "INFO:  == LLM cache == saving: default:extract:e1bd4706b83d796902cb2b43c4e14dc7\n",
            "INFO:  == LLM cache == saving: default:extract:cfef0d8165ed3cad8c40fe1f31975d10\n",
            "INFO: Chunk 37 of 62 extracted 7 Ent + 5 Rel chunk-3ed5041b390df37144e4f8ad8aa2407c\n",
            "INFO:  == LLM cache == saving: default:extract:c5470d059319a9e40b1a94e8a3dd7c83\n",
            "INFO: Chunk 38 of 62 extracted 10 Ent + 6 Rel chunk-6dc5fce7e16ee7b5101cdca9d93723c6\n",
            "INFO:  == LLM cache == saving: default:extract:f8dd99d9e5dae216ad86100ff2b270a3\n",
            "INFO:  == LLM cache == saving: default:extract:032850261843eb782b06f8dad3e89c0f\n",
            "INFO: Chunk 39 of 62 extracted 6 Ent + 6 Rel chunk-c6be0832935fcd0546889ffbcf409e35\n",
            "INFO:  == LLM cache == saving: default:extract:b958a3d8bfa8047cdcce9e4e762fc50a\n",
            "INFO: Chunk 40 of 62 extracted 29 Ent + 9 Rel chunk-cb419ee28b4fb7d5d14b8d16db960da5\n",
            "INFO:  == LLM cache == saving: default:extract:793e3bd7a1eea71cc00f8ff86a5ca838\n",
            "INFO:  == LLM cache == saving: default:extract:63dd0766173bfd3f7917ba7f9fd90d68\n",
            "INFO:  == LLM cache == saving: default:extract:32abe49548f1e6988e0118306bd5f173\n",
            "INFO: Chunk 41 of 62 extracted 6 Ent + 5 Rel chunk-6a1b812bea50ba77161669f02d7d72b1\n",
            "INFO:  == LLM cache == saving: default:extract:162176f6527565bdf230376f4466cb2e\n",
            "INFO:  == LLM cache == saving: default:extract:2449e012d5d6fb01a4959c90a49eabbb\n",
            "INFO: Chunk 42 of 62 extracted 6 Ent + 5 Rel chunk-b3b607e44fc6577fbb85511b8c8174ef\n",
            "INFO:  == LLM cache == saving: default:extract:a1d72bd7cc41367d40ac805f53fc2d95\n",
            "INFO:  == LLM cache == saving: default:extract:d0b02dee4d5dc9c7e62aaa0d84303afa\n",
            "INFO: Chunk 43 of 62 extracted 10 Ent + 7 Rel chunk-7691659eafec589da0b5ef9abd76a72d\n",
            "INFO:  == LLM cache == saving: default:extract:1f57107d2d1c802d7d13ffb31c8aa4a2\n",
            "INFO: Chunk 44 of 62 extracted 6 Ent + 4 Rel chunk-8fbfd96578e665524da0cfa616e65a86\n",
            "INFO:  == LLM cache == saving: default:extract:8d45f06b3202ba6cc670d1339d3d0cbb\n",
            "INFO:  == LLM cache == saving: default:extract:febe09cdfb9b831e454b4ec4de5d019c\n",
            "INFO: Chunk 45 of 62 extracted 8 Ent + 7 Rel chunk-1a7f0e0dd597893dea612dcb08bd5795\n",
            "INFO:  == LLM cache == saving: default:extract:b3f880ef6871a1b7468711829e45e011\n",
            "INFO:  == LLM cache == saving: default:extract:8c1af0aa5ef63b356eceb02d314fc397\n",
            "INFO:  == LLM cache == saving: default:extract:53b96e996acb27def09dc3ca5347cb1a\n",
            "INFO:  == LLM cache == saving: default:extract:f62bb600741474864daaa40630184d58\n",
            "INFO: Chunk 46 of 62 extracted 10 Ent + 9 Rel chunk-643eb428c63e32c69515022da9805f49\n",
            "INFO:  == LLM cache == saving: default:extract:ac2c98cf7fd923a718689b545e4f2779\n",
            "INFO: Chunk 47 of 62 extracted 9 Ent + 6 Rel chunk-bb08644d8d041dc3587c0fe916f5e422\n",
            "INFO:  == LLM cache == saving: default:extract:9325fe8654b00a7d9f5192fb4ab0045b\n",
            "INFO: Chunk 48 of 62 extracted 10 Ent + 8 Rel chunk-c7ef093f3e4f9fdb9b5a5c56d7d5d1a0\n",
            "INFO:  == LLM cache == saving: default:extract:4a7ee7e43b9baa131165f7442d76f506\n",
            "INFO:  == LLM cache == saving: default:extract:cad7fe8eb6f838c2990d68bcdfd53d7b\n",
            "INFO:  == LLM cache == saving: default:extract:28756c68c76dec7ef6ebb893958fcf66\n",
            "INFO:  == LLM cache == saving: default:extract:de188a32119c11ce082adbeb4776b23b\n",
            "INFO: Chunk 49 of 62 extracted 10 Ent + 7 Rel chunk-b7d1f3caaf87a966b3f04a52091e4936\n",
            "INFO:  == LLM cache == saving: default:extract:18ce70baeb57bfe0e06067259e441500\n",
            "INFO:  == LLM cache == saving: default:extract:d92c51fab9fed473790d75b2e08ccccf\n",
            "INFO: Chunk 50 of 62 extracted 11 Ent + 7 Rel chunk-70924a86e13ca1614805ced0344c9652\n",
            "INFO:  == LLM cache == saving: default:extract:d35589129798d416067fe3e9a3b19a5b\n",
            "INFO: Chunk 51 of 62 extracted 8 Ent + 7 Rel chunk-955b24ec512467eb22a572cb51108150\n",
            "INFO:  == LLM cache == saving: default:extract:40799cfa3c3a972b5c740a37d3139d9f\n",
            "INFO: Chunk 52 of 62 extracted 10 Ent + 8 Rel chunk-bfefc4100eec6aa9a5c9581994bca391\n",
            "INFO:  == LLM cache == saving: default:extract:aa881cc592e3237e01e4b48f3f18bffd\n",
            "INFO:  == LLM cache == saving: default:extract:5d0857af9c5c0b70e1efafa39e4383c1\n",
            "INFO: Chunk 53 of 62 extracted 6 Ent + 5 Rel chunk-73c71f440e30ea6f5c99bf253b4ef683\n",
            "INFO:  == LLM cache == saving: default:extract:f53529631b92306a5334800da6d61829\n",
            "INFO:  == LLM cache == saving: default:extract:474ba9ead98844b0758b2292a909384f\n",
            "INFO:openai._base_client:Retrying request to /chat/completions in 0.487195 seconds\n",
            "INFO:  == LLM cache == saving: default:extract:7fd76824e9ce01eca6b7087494de25d1\n",
            "INFO: Chunk 54 of 62 extracted 6 Ent + 5 Rel chunk-7413d361fab2ee1caeb29b3776e3c4ab\n",
            "INFO:  == LLM cache == saving: default:extract:3a0b8d2b751e7ea1f191f66bdb2e304b\n",
            "INFO: Chunk 55 of 62 extracted 7 Ent + 6 Rel chunk-340e7f56591e3e989b26bf78c0fdb07d\n",
            "INFO:  == LLM cache == saving: default:extract:37dd848231529c155d781df519352156\n",
            "INFO:  == LLM cache == saving: default:extract:9cf72731d0b97d3a3dcff936d728b4fa\n",
            "INFO:  == LLM cache == saving: default:extract:1e06667c0a3d4a17c7c4bde7c0744085\n",
            "INFO: Chunk 56 of 62 extracted 8 Ent + 6 Rel chunk-195b645bde5032ad4d87e13a4f8f4327\n",
            "INFO:  == LLM cache == saving: default:extract:523964cf1341e5073fad844cbdc41b25\n",
            "INFO:  == LLM cache == saving: default:extract:1dc6c5454b6cb277e58a43e5c08b142b\n",
            "INFO:  == LLM cache == saving: default:extract:bd744a940086d13581fdf7daf60d289f\n",
            "INFO: Chunk 57 of 62 extracted 7 Ent + 5 Rel chunk-38c63b51fc7bf0f85272dca6589bea3d\n",
            "INFO:  == LLM cache == saving: default:extract:bdac6a490eb3c906dc36e4d0167bde9b\n",
            "INFO: Chunk 58 of 62 extracted 7 Ent + 6 Rel chunk-fa74f2e38edf6deae4f7d4ba167967d0\n",
            "INFO:  == LLM cache == saving: default:extract:f9ec5b1271df63d8d9faddf4b7cafa89\n",
            "INFO: Chunk 59 of 62 extracted 9 Ent + 7 Rel chunk-385615b089cbc14a5ada42e762dd646a\n",
            "INFO:  == LLM cache == saving: default:extract:12a025073312998661aa965ae7595f6a\n",
            "INFO:  == LLM cache == saving: default:extract:08f412d79bbe473cf8b06020feb7efe7\n",
            "INFO:  == LLM cache == saving: default:extract:0dde4bc47f0c675c8ecd9b69cd31ffe1\n",
            "INFO:  == LLM cache == saving: default:extract:3543486fd805d6a2bd4b0406bbbd8818\n",
            "INFO: Chunk 60 of 62 extracted 4 Ent + 4 Rel chunk-92cf62fb83d9ab807b3b4a068e4f7ba3\n",
            "INFO:  == LLM cache == saving: default:extract:94fea1d4714a126bf7e86423fd5675d1\n",
            "INFO: Chunk 61 of 62 extracted 6 Ent + 5 Rel chunk-2e85997f2216da8c774d8461ca9300d2\n",
            "INFO:  == LLM cache == saving: default:extract:608de6d67b1635611c6651759afed3bc\n",
            "INFO: Chunk 62 of 62 extracted 10 Ent + 8 Rel chunk-a2d7710c2613eced69ffb50b0a6ad1f8\n",
            "INFO: Merging stage 1/1: unknown_source\n",
            "INFO: Phase 1: Processing 434 entities from doc-879378d49c3aba1929a7b43d4e9914f9 (async: 8)\n",
            "INFO:  == LLM cache == saving: default:summary:7f91f96a3d27137394df0811d9d2e531\n",
            "INFO: LLMmrg: `Stig` | 0+9\n",
            "INFO: Phase 2: Processing 383 relations from doc-879378d49c3aba1929a7b43d4e9914f9 (async: 8)\n",
            "INFO: Chunks appended from relation: `Member Organizations`\n",
            "INFO: Chunks appended from relation: `Data Quality`\n",
            "INFO: Chunks appended from relation: `System`\n",
            "INFO: Chunks appended from relation: `Data Owners`\n",
            "INFO: Phase 3: Updating final 443(434+9) entities and  383 relations from doc-879378d49c3aba1929a7b43d4e9914f9\n",
            "INFO: Completed merging: 434 entities, 9 extra entities, 383 relations\n",
            "INFO: [_] Writing graph with 443 nodes, 383 edges\n",
            "INFO: In memory DB persist to disk\n",
            "INFO: Completed processing file 1/1: unknown_source\n",
            "INFO: Enqueued document processing pipeline stopped\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightRAG insertion complete.\n"
          ]
        }
      ],
      "source": [
        "# Insert the prepared contexts into LightRAG\n",
        "\n",
        "if not contexts:\n",
        "    raise ValueError(\"No contexts loaded; run the previous cell first.\")\n",
        "\n",
        "print(f\"Inserting {len(contexts)} contexts into LightRAG (this may take a while)...\")\n",
        "\n",
        "# We join the contexts into a single large document so LightRAG can re-chunk as needed.\n",
        "joined_contexts = \"\\n\\n\".join(contexts)\n",
        "\n",
        "await rag.ainsert(joined_contexts)\n",
        "\n",
        "print(\"LightRAG insertion complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing embeddings for contexts (one-time)...\n"
          ]
        }
      ],
      "source": [
        "# Semantic search helper: find relevant segments and return video/timestamp metadata\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Base URL for building clickable links; adjust to your eventual video player.\n",
        "VIDEO_BASE_URL = os.getenv(\"VIDEO_BASE_URL\")\n",
        "\n",
        "# Pre-compute embeddings for all contexts using the same embedding function as LightRAG\n",
        "print(\"Computing embeddings for contexts (one-time)...\")\n",
        "context_embeddings = await rag.embedding_func(contexts)\n",
        "context_embeddings = np.array(context_embeddings, dtype=\"float32\")\n",
        "context_norms = np.linalg.norm(context_embeddings, axis=1) + 1e-8\n",
        "\n",
        "\n",
        "async def search_segments_async(query: str, top_k: int = 5):\n",
        "    \"\"\"Semantic search over transcript segments.\n",
        "\n",
        "    Returns a list of dicts with video_id, start, end, text, score, and a URL\n",
        "    you can later hook up to a player.\n",
        "    \"\"\"\n",
        "\n",
        "    query_emb = await rag.embedding_func([query])\n",
        "    query_emb = np.array(query_emb, dtype=\"float32\")[0]\n",
        "    query_norm = np.linalg.norm(query_emb) + 1e-8\n",
        "\n",
        "    # Cosine similarity between query and all context embeddings\n",
        "    sims = (context_embeddings @ query_emb) / (context_norms * query_norm)\n",
        "    top_idx = np.argsort(-sims)[:top_k]\n",
        "\n",
        "    results = []\n",
        "    for idx in top_idx:\n",
        "        meta = contexts_meta[int(idx)].copy()\n",
        "        meta[\"score\"] = float(sims[idx])\n",
        "        # Build a simple URL that encodes video + start time\n",
        "        meta[\"url\"] = f\"{VIDEO_BASE_URL}/{meta['video_id']}?t={int(meta['start'])}\"\n",
        "        results.append(meta)\n",
        "\n",
        "    # Pretty-print results for quick inspection\n",
        "    for r in results:\n",
        "        print(\n",
        "            f\"- video_id={r['video_id']} start={r['start']:.2f}s end={r['end']:.2f}s score={r['score']:.3f}\"\n",
        "        )\n",
        "        print(f\"  url: {r['url']}\")\n",
        "        print(f\"  text: {r['text'][:200]}...\")\n",
        "        print()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage in a notebook cell:\n",
        "#   await search_segments_async(\"data sharing platform\", top_k=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 1660 records to /Users/adi/digdir-video-ai/transcripts/chunks_for_db.jsonl.\n",
            "You can load this JSONL into Postgres, Neo4j, or another vector DB as needed.\n"
          ]
        }
      ],
      "source": [
        "# Export chunks + metadata for external vector/graph stores (PostgreSQL, Neo4j, etc.)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(\"transcripts\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "export_jsonl_path = output_dir / \"chunks_for_db.jsonl\"\n",
        "\n",
        "records_written = 0\n",
        "with export_jsonl_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for meta in contexts_meta:\n",
        "        rec = {\n",
        "            \"video_id\": meta[\"video_id\"],\n",
        "            \"segment_id\": meta[\"segment_id\"],\n",
        "            \"start\": meta[\"start\"],\n",
        "            \"end\": meta[\"end\"],\n",
        "            \"text\": meta[\"text\"],\n",
        "            # Same URL pattern used in search_segments_async\n",
        "            \"url\": f\"{VIDEO_BASE_URL}/{meta['video_id']}?t={int(meta['start'])}\",\n",
        "        }\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "        records_written += 1\n",
        "\n",
        "print(f\"Wrote {records_written} records to {export_jsonl_path.resolve()}.\")\n",
        "print(\"You can load this JSONL into Postgres, Neo4j, or another vector DB as needed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1660 records from transcripts/chunks_for_db.jsonl.\n",
            "Inserted/updated 1660 rows into video_segments.\n",
            "You can now attach pgvector or another embedding column if desired.\n"
          ]
        }
      ],
      "source": [
        "# Load exported chunks into PostgreSQL (vector-ready table)\n",
        "\n",
        "import json\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "\n",
        "if not POSTGRES_DSN:\n",
        "    raise RuntimeError(\"POSTGRES_DSN is not set. Export POSTGRES_DSN before running this cell.\")\n",
        "\n",
        "try:\n",
        "    psycopg2 = importlib.import_module(\"psycopg2\")\n",
        "except ImportError:\n",
        "    raise ImportError(\"psycopg2 is not installed. Install it with `%pip install psycopg2-binary`.\")\n",
        "\n",
        "export_jsonl_path = Path(\"transcripts/chunks_for_db.jsonl\")\n",
        "if not export_jsonl_path.exists():\n",
        "    raise FileNotFoundError(f\"Export file not found: {export_jsonl_path}\")\n",
        "\n",
        "records: list[dict] = []\n",
        "with export_jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        records.append(json.loads(line))\n",
        "\n",
        "print(f\"Loaded {len(records)} records from {export_jsonl_path}.\")\n",
        "\n",
        "with psycopg2.connect(POSTGRES_DSN) as conn:\n",
        "    with conn.cursor() as cur:\n",
        "        # Create a simple table for video segments (one row per chunk)\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS video_segments (\n",
        "                id SERIAL PRIMARY KEY,\n",
        "                video_id TEXT NOT NULL,\n",
        "                segment_id INTEGER,\n",
        "                start DOUBLE PRECISION,\n",
        "                \"end\" DOUBLE PRECISION,\n",
        "                text TEXT,\n",
        "                url TEXT,\n",
        "                UNIQUE (video_id, segment_id, start)\n",
        "            );\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        insert_sql = \"\"\"\n",
        "            INSERT INTO video_segments (video_id, segment_id, start, \"end\", text, url)\n",
        "            VALUES (%(video_id)s, %(segment_id)s, %(start)s, %(end)s, %(text)s, %(url)s)\n",
        "            ON CONFLICT (video_id, segment_id, start) DO UPDATE\n",
        "            SET \"end\" = EXCLUDED.\"end\", text = EXCLUDED.text, url = EXCLUDED.url;\n",
        "        \"\"\"\n",
        "        cur.executemany(insert_sql, records)\n",
        "    conn.commit()\n",
        "\n",
        "print(f\"Inserted/updated {len(records)} rows into video_segments.\")\n",
        "print(\"You can now attach pgvector or another embedding column if desired.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1660 records from transcripts/chunks_for_db.jsonl.\n",
            "Upserted 1660 VideoSegment nodes (and Video parents) into Neo4j.\n"
          ]
        }
      ],
      "source": [
        "# Load exported chunks into Neo4j as Video / VideoSegment graph\n",
        "\n",
        "import json\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "\n",
        "if not (NEO4J_URI and NEO4J_USER and NEO4J_PASSWORD):\n",
        "    raise RuntimeError(\"NEO4J_URI / NEO4J_USER / NEO4J_PASSWORD must be set before running this cell.\")\n",
        "\n",
        "try:\n",
        "    neo4j_module = importlib.import_module(\"neo4j\")\n",
        "except ImportError:\n",
        "    raise ImportError(\"neo4j Python driver is not installed. Install it with `%pip install neo4j`.\\n\")\n",
        "\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "export_jsonl_path = Path(\"transcripts/chunks_for_db.jsonl\")\n",
        "if not export_jsonl_path.exists():\n",
        "    raise FileNotFoundError(f\"Export file not found: {export_jsonl_path}\")\n",
        "\n",
        "records: list[dict] = []\n",
        "with export_jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        records.append(json.loads(line))\n",
        "\n",
        "print(f\"Loaded {len(records)} records from {export_jsonl_path}.\")\n",
        "\n",
        "\n",
        "def _ingest_segment_tx(tx, rec: dict):\n",
        "    tx.run(\n",
        "        \"\"\"\n",
        "        MERGE (v:Video {video_id: $video_id})\n",
        "        MERGE (s:VideoSegment {\n",
        "            video_id: $video_id,\n",
        "            segment_id: $segment_id,\n",
        "            start: $start\n",
        "        })\n",
        "        SET s.end = $end,\n",
        "            s.text = $text,\n",
        "            s.url = $url\n",
        "        MERGE (v)-[:HAS_SEGMENT]->(s)\n",
        "        \"\"\",\n",
        "        **rec,\n",
        "    )\n",
        "\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "\n",
        "with driver.session() as session:\n",
        "    for rec in records:\n",
        "        session.execute_write(_ingest_segment_tx, rec)\n",
        "\n",
        "driver.close()\n",
        "\n",
        "print(f\"Upserted {len(records)} VideoSegment nodes (and Video parents) into Neo4j.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- video_id=video2 start=3057.10s end=3061.10s score=0.591\n",
            "  url: file:///Users/adi/digdir-video-ai/videos/video2?t=3057\n",
            "  text: Vi snakker om datamesh, vi snakker om datafabrik og så videre....\n",
            "\n",
            "- video_id=video2 start=3027.10s end=3033.10s score=0.574\n",
            "  url: file:///Users/adi/digdir-video-ai/videos/video2?t=3027\n",
            "  text: Det som er viktig for oss er at vi får en plattform og har en plattform som vi kan bygge videre på....\n",
            "\n",
            "- video_id=video2 start=3039.10s end=3057.10s score=0.567\n",
            "  url: file:///Users/adi/digdir-video-ai/videos/video2?t=3039\n",
            "  text: så tror vi jo veldig på at vi kan utvide funksjonaliteten og gjøre den plattformen egnet for fremtidige eller moderne dataarkitekturer fremover....\n",
            "\n",
            "- video_id=video1 start=2231.58s end=2232.58s score=0.548\n",
            "  url: file:///Users/adi/digdir-video-ai/videos/video1?t=2231\n",
            "  text: det er å dele datadelen....\n",
            "\n",
            "- video_id=video2 start=2443.10s end=2446.10s score=0.539\n",
            "  url: file:///Users/adi/digdir-video-ai/videos/video2?t=2443\n",
            "  text: og det som faktisk skjer nede på gulvet hos de som utvikler....\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example semantic query\n",
        "query = \"Når snakker de om datadeling og plattform?\"\n",
        "results = await search_segments_async(query, top_k=5)\n",
        "\n",
        "len(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('video2',\n",
              " 3057.1,\n",
              " 'Vi snakker om datamesh, vi snakker om datafabrik og så videre.')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hit = results[0]  # or any index\n",
        "hit[\"video_id\"], hit[\"start\"], hit[\"text\"][:120]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "def show_video_segment(video_path: str, start: float, width: int = 640):\n",
        "    \"\"\"Embed a local video in the notebook and seek to `start` seconds.\n",
        "\n",
        "    Works best when the video is inside the project directory (e.g. `videos/video2.mp4`).\n",
        "    If an absolute path is passed, it will be made relative to the current working directory\n",
        "    when possible so Jupyter can serve the file.\n",
        "    \"\"\"\n",
        "    p = Path(video_path)\n",
        "    try:\n",
        "        # Try to make path relative to notebook root so Jupyter can serve it\n",
        "        p_rel = p.relative_to(Path(os.getcwd()))\n",
        "    except ValueError:\n",
        "        # Fall back to original path\n",
        "        p_rel = p\n",
        "\n",
        "    src = p_rel.as_posix()\n",
        "\n",
        "    return HTML(f\"\"\"\n",
        "    <video id=\"segment_player\" width=\"{width}\" controls>\n",
        "      <source src=\"{src}\" type=\"video/mp4\">\n",
        "      Your browser does not support the video tag.\n",
        "    </video>\n",
        "    <script>\n",
        "      const v = document.getElementById('segment_player');\n",
        "      v.addEventListener('loadedmetadata', () => {{\n",
        "        v.currentTime = {int(start)};\n",
        "      }});\n",
        "    </script>\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <video id=\"segment_player\" width=\"640\" controls>\n",
              "      <source src=\"videos/video2.mp4\" type=\"video/mp4\">\n",
              "      Your browser does not support the video tag.\n",
              "    </video>\n",
              "    <script>\n",
              "      const v = document.getElementById('segment_player');\n",
              "      v.addEventListener('loadedmetadata', () => {\n",
              "        v.currentTime = 3057;\n",
              "      });\n",
              "    </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "show_video_segment(hit[\"video_path\"], hit[\"start\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
